{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11e246b",
   "metadata": {},
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    " CREATE SEVERAL (3+) TABLES HERE\n",
    "\"\"\"} ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
    "WRITE IN YOUR CONTEXT QUERIES HERE\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT employee_name\n",
      "FROM employees\n",
      "WHERE salary = (SELECT MAX(salary) FROM employees);\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"\"\"Find the employee who earns the highest salary\"\"\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT e.name, s.salary\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query selects the name and salary of the employee who earns the highest salary by joining the \"employees\" and \"salary\" tables on the employee ID. It then orders the results by salary in descending order and limits the output to only the top result, which is the employee with the highest salary.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"Find the employee who earns the highest salary\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT year, AVG(salary) AS average_salary\n",
      "FROM employees\n",
      "GROUP BY year;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"Show the average salary grouped by year\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT year, AVG(salary) AS average_salary\n",
      "FROM salary\n",
      "GROUP BY year;\n",
      "```\n",
      "\n",
      "This SQL query selects the year and calculates the average salary for each year by grouping the data based on the year column in the salary table.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"Show the average salary grouped by year\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec6833c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Variation 1 - New Context\n",
      "```sql\n",
      "SELECT * \n",
      "FROM employees\n",
      "WHERE salary > 60000;\n",
      "```\n",
      "\n",
      "### Variation 1 - Old Context\n",
      "This is your SQL:\n",
      "```sql\n",
      "SELECT employees.name\n",
      "FROM employees\n",
      "JOIN salary ON employees.ID_usr = salary.ID_usr\n",
      "WHERE salary.salary > 60000;\n",
      "```\n",
      "\n",
      "This SQL query retrieves the names of employees who earn more than 60000 by joining the \"employees\" table with the \"salary\" table on the ID_usr column and filtering the results based on the salary amount.\n",
      "\n",
      "\n",
      "### Variation 2 - New Context\n",
      "```sql\n",
      "SELECT year, AVG(salary) AS average_salary\n",
      "FROM employees\n",
      "GROUP BY year;\n",
      "```\n",
      "\n",
      "### Variation 2 - Old Context\n",
      "This is your SQL:\n",
      "```sql\n",
      "SELECT year, AVG(salary) AS average_salary\n",
      "FROM salary\n",
      "GROUP BY year;\n",
      "```\n",
      "\n",
      "This SQL query selects the year and calculates the average salary for each year from the \"salary\" table. The results are grouped by year using the GROUP BY clause, and the AVG() function is used to calculate the average salary for each year.\n",
      "\n",
      "\n",
      "### Variation 3 - New Context\n",
      "```sql\n",
      "SELECT e.employee_name, e.institution_of_study\n",
      "FROM employees e;\n",
      "```\n",
      "\n",
      "### Variation 3 - Old Context\n",
      "This is your SQL:\n",
      "```sql\n",
      "SELECT e.name, s.Institution\n",
      "FROM employees e\n",
      "JOIN studies s ON e.ID_usr = s.ID_usr;\n",
      "```\n",
      "\n",
      "This SQL query selects the names of employees and their institutions of study by joining the \"employees\" table with the \"studies\" table on the common column \"ID_usr\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================================================================\n",
    "context_user = context.copy()\n",
    "old_context_user = old_context.copy()\n",
    "\n",
    "print(\"### Variation 1 - New Context\")\n",
    "print(return_CCRMSQL(\"Find all employees who earn more than 60000\", context_user))\n",
    "\n",
    "print(\"\\n### Variation 1 - Old Context\")\n",
    "print(return_CCRMSQL(\"Find all employees who earn more than 60000\", old_context_user))\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================================================================\n",
    "context_user = context.copy()\n",
    "old_context_user = old_context.copy()\n",
    "\n",
    "print(\"\\n\\n### Variation 2 - New Context\")\n",
    "print(return_CCRMSQL(\"Show the average salary by year\", context_user))\n",
    "\n",
    "print(\"\\n### Variation 2 - Old Context\")\n",
    "print(return_CCRMSQL(\"Show the average salary by year\", old_context_user))\n",
    "\n",
    "\n",
    "# =============================================================================================\n",
    "context_user = context.copy()\n",
    "old_context_user = old_context.copy()\n",
    "\n",
    "print(\"\\n\\n### Variation 3 - New Context\")\n",
    "print(return_CCRMSQL(\"List the employees with their institution of study\", context_user))\n",
    "\n",
    "print(\"\\n### Variation 3 - Old Context\")\n",
    "print(return_CCRMSQL(\"List the employees with their institution of study\", old_context_user))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9b354",
   "metadata": {},
   "source": [
    "Report on SQL Query Generation with GPT\n",
    "\n",
    "In this lab I worked on using GPT to make SQL queries. I tried two different kinds of prompts: the old one, where tables were written in a JSON style, and the new one, where tables were written with CREATE TABLE plus sample data and some example queries. The goal was to see which one worked better.\n",
    "\n",
    "What I Found\n",
    "\n",
    "When I asked questions like “Who is the highest paid employee?” or “Which institution has the highest average salary?”, the new prompt usually gave better answers. The SQL was correct, it used the right tables, and it added joins when needed. It also explained the result clearly.\n",
    "\n",
    "The old prompt sometimes worked but not always. A few times it gave me SQL that was missing things, like not using GROUP BY when it should, or it even made up a column that didn’t exist. That showed me that the old style is less reliable.\n",
    "\n",
    "What I Learned\n",
    "\n",
    "I learned that the way I write the prompt really matters. The new style with CREATE TABLE, sample rows, and examples helped GPT a lot. It made the answers more accurate and less random. The old style made GPT more likely to guess or “hallucinate.”\n",
    "\n",
    "Another thing I learned is that GPT can look very confident even when the answer is wrong. So it’s important to double-check the SQL before using it.\n",
    "\n",
    "Overall, the main lesson is: clearer prompts = better results. The new method worked way better, and now I understand how important it is to guide the model with the right context."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
